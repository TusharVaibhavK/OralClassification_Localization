# Oral Cancer Classification ğŸ¦· ğŸ”¬

An AI-powered system for classifying oral lesions as benign or malignant using deep learning models.

## ğŸ§  Models Overview

This project implements four powerful deep learning models for oral cancer classification:

### 1. UNet Model ğŸŒ

The UNet architecture, originally designed for biomedical image segmentation, has been adapted for classification tasks:

- **Architecture**: Encoder-decoder structure with skip connections
- **Key Features**:
  - Preserves spatial information through skip connections
  - Efficient feature extraction with downsampling/upsampling paths
  - Global average pooling followed by classification head
- **Implementation**: Unet.py
- **Demo Application**: app.py

### 2. AttentionNet ğŸ‘ï¸

An enhanced classification model with attention mechanisms:

- **Architecture**: Based on ResNet50 with added attention mechanisms
- **Key Features**:
  - Channel attention modules for focusing on important feature channels
  - Spatial attention for highlighting relevant regions in the image
  - Visualization of attention maps to show which areas influenced the model's decision
- **Implementation**: model.py
- **Demo Application**: app1.py
- **Training Script**: train.py

### 3. DeepLab Model ğŸ–¼ï¸

A semantic segmentation model adapted for classification tasks:

- **Architecture**: DeepLabV3+ with atrous convolution for capturing multi-scale context
- **Key Features**:
  - Atrous Spatial Pyramid Pooling (ASPP) for extracting features at multiple scales
  - Fine-tuned for classification tasks
  - Robust to variations in lesion size and shape
- **Implementation**: deeplab.py
- **Demo Application**: deeplab_app.py
- **Training Script**: deeplab_train.py

### 4. Transformer Model ğŸ”„

A cutting-edge model leveraging transformer-based architectures:

- **Architecture**: Vision Transformer (ViT) adapted for image classification
- **Key Features**:
  - Self-attention mechanism for capturing global dependencies
  - Patch-based image representation
  - High accuracy on complex datasets
- **Implementation**: transformer.py
- **Demo Application**: transformer_app.py
- **Training Script**: transformer_train.py

## ğŸš€ Project Setup

### Prerequisites

- Python 3.8+ ğŸ
- PyTorch 1.8+ ğŸ”¥
- CUDA-capable GPU (recommended) âš¡

### Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/TusharVaibhavK/OralCancerClassification.git
   cd OralCancerClassification
   ```

2. Create and activate a virtual environment:
   ```bash
   python -m venv venv
   
   # Windows
   venv\Scripts\activate
   
   # macOS/Linux
   source venv/bin/activate
   ```

3. Install required packages:
   ```bash
   pip install torch torchvision tqdm matplotlib scikit-learn seaborn streamlit pillow
   ```

## ğŸ’» Usage

### Training Models

#### Train AttentionNet:
```bash
python -m AttentionNet.train
```

#### Train UNet:
```bash
python -m Unet.Unet
```

#### Train DeepLabV3+:
```bash
python -m DeepLabV3+.deeplab
```

#### Train Transformer:
```bash
python -m TransformerSegamentationNetwork.train_full_pipeline
```

### Running Applications

#### AttentionNet Web Interface:
```bash
streamlit run AttentionNet/app1.py
```

#### UNet Web Interface:
```bash
streamlit run Unet/app.py
```

#### DeepLabV3+ Web Interface:
```bash
streamlit run DeepLabV3+/main.py
```

#### Transformer-segmentation Network Web Interface:
```bash
streamlit run TransformerSegmentationNetwork/classification_ui.py
```

### Visualizing Attention Maps

```bash
python -m AttentionNet.visualize_attention --image_dir your_image_directory --num_images 5
```

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ AttentionNet/               # AttentionNet implementation
â”‚   â”œâ”€â”€ results/                # Results and evaluation metrics
â”‚   â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”‚   â””â”€â”€ training_history.png
â”‚   â”œâ”€â”€ app1.py                 # Streamlit web application
â”‚   â”œâ”€â”€ model.py                # AttentionNet model architecture
â”‚   â”œâ”€â”€ train.py                # Training script
â”‚   â””â”€â”€ visualize_attention.py  # Script for visualizing attention maps
â”œâ”€â”€ DeepLabV3+/                 # DeepLab implementation
â”‚   â”œâ”€â”€ results/                # Results and evaluation metrics
â”‚   â”‚   â”œâ”€â”€ deep_model.pth
â”‚   â”‚   â”œâ”€â”€ roc_curve.png
â”‚   â”œâ”€â”€ deeplab.py              # DeepLab model architecture
â”‚   â”œâ”€â”€ main.py                 # Streamlit web application
â”‚   â””â”€â”€ model_analysis.py       # Script for analyzing model performance
â”œâ”€â”€ Oral Images Dataset/        # Dataset folder (placeholder for images)
â”œâ”€â”€ TransformerSegmentationNetwork/  # Transformer implementation
â”‚   â”œâ”€â”€ __pycache__/            # Python cache files
â”‚   â”œâ”€â”€ results/                # Results and evaluation metrics
â”‚   â”‚   â”œâ”€â”€ best_model.pth
â”‚   â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”‚   â”œâ”€â”€ oral_cancer_model.pth
â”‚   â”‚   â”œâ”€â”€ oral_cancer_resnet50.pth
â”‚   â”‚   â””â”€â”€ roc_curve.png
â”‚   â”œâ”€â”€ classification_ui.py    # Streamlit web application
â”‚   â”œâ”€â”€ curve.py                # Script for plotting curves
â”‚   â””â”€â”€ train_full_pipeline.py  # Training script for the full pipeline
â”œâ”€â”€ Unet/                       # UNet implementation
â”‚   â”œâ”€â”€ results/                # Results and evaluation metrics
â”‚   â”‚   â”œâ”€â”€ model.pth
â”‚   â”‚   â”œâ”€â”€ results.png
â”‚   â”‚   â””â”€â”€ roc_curve.png
â”‚   â”œâ”€â”€ app.py                  # Streamlit web application
â”‚   â”œâ”€â”€ model_analysis.py       # Script for analyzing model performance
â”‚   â””â”€â”€ Unet.py                 # UNet model architecture and training
â”œâ”€â”€ .gitignore                  # Git ignore file
â”œâ”€â”€ model.pth                   # Placeholder for model weights
â””â”€â”€ README.md                   # Project documentation

```

## ğŸ” Results

Models are evaluated based on:
- Accuracy
- Precision
- Recall
- F1 Score
- Confusion Matrix

Visualizations of attention maps help explain which regions of the image contributed most to the classification decision.
